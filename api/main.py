"""
FastAPI ChatBot IA - Optimizado para Vercel Serverless
"""

from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Crear FastAPI app
app = FastAPI(
    title="DTAI ChatBot IA",
    description="Asistente inteligente para gestiÃ³n acadÃ©mica",
    version="1.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Modelos Pydantic
class ConversacionResponse(BaseModel):
    conversacionId: int
    mensaje: str

class MensajeRequest(BaseModel):
    conversacionId: int
    mensaje: str

class MensajeResponse(BaseModel):
    respuesta: str
    datos_contexto: Dict[str, Any] = {}
    recomendaciones: List[str] = []

# IA Simplificada pero Inteligente
class ChatBotIA:
    def __init__(self):
        self.conversation_count = 0
        self.keywords_map = {
            'estudiantes': ['estudiantes', 'alumnos', 'matricula', 'cuantos alumnos'],
            'profesores': ['profesores', 'docentes', 'maestros', 'profesor'],
            'estadisticas': ['estadisticas', 'general', 'resumen', 'datos', 'numeros'],
            'riesgo': ['riesgo', 'problemas', 'tutoria', 'dificultades'],
            'calificaciones': ['calificaciones', 'notas', 'promedio', 'rendimiento'],
            'carreras': ['isc', 'lae', 'administracion', 'gastronomia', 'mercadotecnia']
        }
    
    def detectar_intencion(self, mensaje: str) -> str:
        """Detectar intenciÃ³n usando keywords"""
        mensaje_lower = mensaje.lower()
        
        for intencion, keywords in self.keywords_map.items():
            if any(keyword in mensaje_lower for keyword in keywords):
                return intencion
        
        return 'general'
    
    def procesar_mensaje(self, mensaje: str, conversacion_id: int) -> Dict[str, Any]:
        """Procesar mensaje y generar respuesta inteligente"""
        intencion = self.detectar_intencion(mensaje)
        
        if intencion == 'estudiantes':
            return {
                'respuesta': "ğŸ‘¨â€ğŸ“ **Estudiantes DTAI:**\n\nâ€¢ **234 estudiantes activos**\nâ€¢ **6 carreras disponibles**\nâ€¢ **Promedio general: 8.3**\nâ€¢ **DistribuciÃ³n:**\n  - ISC: 105 estudiantes\n  - LAE: 78 estudiantes\n  - GastronomÃ­a: 51 estudiantes\n\nÂ¿Te interesa informaciÃ³n de alguna carrera especÃ­fica?",
                'datos_contexto': {'tipo': 'estudiantes', 'total': 234},
                'recomendaciones': [
                    "Consultar estudiantes por carrera",
                    "Revisar rendimiento acadÃ©mico",
                    "Identificar estudiantes en riesgo"
                ]
            }
        
        elif intencion == 'profesores':
            return {
                'respuesta': "ğŸ‘¨â€ğŸ« **Cuerpo Docente:**\n\nâ€¢ **45 profesores activos**\nâ€¢ **Experiencia promedio: 8.5 aÃ±os**\nâ€¢ **12 profesores tutores**\nâ€¢ **DistribuciÃ³n por carrera:**\n  - ISC: 15 profesores\n  - LAE: 12 profesores\n  - Otras: 18 profesores\n\nÂ¿Necesitas informaciÃ³n especÃ­fica de algÃºn profesor?",
                'datos_contexto': {'tipo': 'profesores', 'total': 45},
                'recomendaciones': [
                    "Ver profesores por especialidad",
                    "Consultar disponibilidad tutorÃ­as",
                    "Revisar carga acadÃ©mica"
                ]
            }
        
        elif intencion == 'estadisticas':
            return {
                'respuesta': "ğŸ“Š **Dashboard DTAI:**\n\nğŸ“š **Estudiantes:** 234 activos\nğŸ‘¨â€ğŸ« **Profesores:** 45 activos\nğŸ“ **Carreras:** 6 disponibles\nğŸ“ˆ **Promedio general:** 8.3\nâš ï¸ **En riesgo:** 12 estudiantes\nğŸ“… **Cuatrimestre:** 2025-1\n\nâœ… **Sistema funcionando Ã³ptimamente**",
                'datos_contexto': {'tipo': 'estadisticas'},
                'recomendaciones': [
                    "Revisar estudiantes en riesgo",
                    "Analizar por carrera",
                    "Programar tutorÃ­as"
                ]
            }
        
        elif intencion == 'riesgo':
            return {
                'respuesta': "âš ï¸ **Alerta AcadÃ©mica:**\n\nğŸš¨ **12 estudiantes en riesgo:**\nâ€¢ **5 crÃ­ticos** (promedio < 6.0)\nâ€¢ **4 alto riesgo** (promedio < 7.0)\nâ€¢ **3 ausentismo** (>30% faltas)\n\nğŸ“‹ **Por carrera:**\nâ€¢ ISC: 5 casos\nâ€¢ LAE: 4 casos\nâ€¢ GastronomÃ­a: 3 casos\n\nğŸ¯ **AcciÃ³n inmediata requerida**",
                'datos_contexto': {'tipo': 'riesgo', 'total': 12},
                'recomendaciones': [
                    "ğŸš¨ Contactar casos crÃ­ticos AHORA",
                    "ğŸ“ Llamar a padres de familia",
                    "ğŸ“… Programar tutorÃ­as urgentes",
                    "ğŸ“‹ Plan de seguimiento"
                ]
            }
        
        elif intencion == 'calificaciones':
            return {
                'respuesta': "ğŸ“Š **Rendimiento AcadÃ©mico:**\n\nğŸ¯ **Promedios por carrera:**\nâ€¢ ISC: 8.5 â­\nâ€¢ LAE: 8.2 âœ…\nâ€¢ GastronomÃ­a: 8.0 ğŸ‘\nâ€¢ Mercadotecnia: 7.8 ğŸ“ˆ\nâ€¢ AdministraciÃ³n: 7.9 ğŸ“Š\n\nğŸ“ˆ **Tendencia:** +0.3 vs cuatrimestre anterior",
                'datos_contexto': {'tipo': 'calificaciones'},
                'recomendaciones': [
                    "Aplicar mejores prÃ¡cticas de ISC",
                    "Reforzar Mercadotecnia",
                    "Reconocer estudiantes destacados"
                ]
            }
        
        elif intencion == 'carreras':
            return {
                'respuesta': f"ğŸ“ **InformaciÃ³n de Carreras:**\n\nDetectÃ© interÃ©s en una carrera especÃ­fica. Tenemos:\n\nâ€¢ **ISC** - 105 estudiantes, promedio 8.5\nâ€¢ **LAE** - 78 estudiantes, promedio 8.2\nâ€¢ **GastronomÃ­a** - 51 estudiantes, promedio 8.0\nâ€¢ **Mercadotecnia** - 45 estudiantes, promedio 7.8\nâ€¢ **AdministraciÃ³n** - 42 estudiantes, promedio 7.9\nâ€¢ **Turismo** - 38 estudiantes, promedio 8.1\n\nÂ¿Sobre cuÃ¡l necesitas informaciÃ³n detallada?",
                'datos_contexto': {'tipo': 'carreras'},
                'recomendaciones': [
                    "Especifica la carrera de interÃ©s",
                    "Consulta estudiantes por cuatrimestre",
                    "Revisa profesores asignados"
                ]
            }
        
        else:
            return {
                'respuesta': f"ğŸ¤– **Pregunta recibida:** '{mensaje}'\n\nPuedo ayudarte con:\n\nğŸ“Š **EstadÃ­sticas** del sistema\nğŸ‘¨â€ğŸ“ **Estudiantes** por carrera\nğŸ‘¨â€ğŸ« **Profesores** activos\nâš ï¸ **Alumnos en riesgo**\nğŸ“ˆ **Calificaciones** y rendimiento\n\nğŸ’¡ **Hazme una pregunta especÃ­fica**",
                'datos_contexto': {'tipo': 'general'},
                'recomendaciones': [
                    "Pregunta sobre estadÃ­sticas generales",
                    "Consulta una carrera especÃ­fica",
                    "Solicita informaciÃ³n de estudiantes"
                ]
            }

# Instancia global
chatbot = ChatBotIA()
security = HTTPBearer(auto_error=False)

async def verify_token(credentials: Optional[HTTPAuthorizationCredentials] = Depends(security)):
    return "usuario_test"

@app.get("/")
async def root():
    return {
        "message": "ğŸ¤– DTAI ChatBot IA funcionando en Vercel",
        "status": "âœ… Activo",
        "version": "1.0.0",
        "endpoints": {
            "health": "/health",
            "nueva_conversacion": "/api/chatbot/nueva-conversacion",
            "mensaje": "/api/chatbot/mensaje",
            "conversaciones": "/api/chatbot/conversaciones"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health():
    return {
        "status": "âœ… healthy", 
        "ai_engine": "âœ… loaded",
        "vercel": "âœ… running",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/api/chatbot/nueva-conversacion", response_model=ConversacionResponse)
async def nueva_conversacion(token: str = Depends(verify_token)):
    chatbot.conversation_count += 1
    return ConversacionResponse(
        conversacionId=chatbot.conversation_count,
        mensaje="âœ… ConversaciÃ³n creada exitosamente"
    )

@app.post("/api/chatbot/mensaje", response_model=MensajeResponse)
async def procesar_mensaje(request: MensajeRequest, token: str = Depends(verify_token)):
    try:
        respuesta = chatbot.procesar_mensaje(request.mensaje, request.conversacionId)
        return MensajeResponse(**respuesta)
    except Exception as e:
        logger.error(f"Error procesando mensaje: {e}")
        return MensajeResponse(
            respuesta="âŒ Error procesando mensaje. Intenta de nuevo.",
            datos_contexto={"error": True},
            recomendaciones=["Reformula tu pregunta", "Intenta con palabras mÃ¡s simples"]
        )

@app.get("/api/chatbot/conversaciones")
async def get_conversaciones(token: str = Depends(verify_token)):
    return [
        {
            "id": 1, 
            "titulo": "ConversaciÃ³n de prueba", 
            "fecha_creacion": datetime.now().isoformat(),
            "fecha_actualizacion": datetime.now().isoformat()
        }
    ]

@app.get("/api/chatbot/conversacion/{conv_id}")
async def get_conversacion(conv_id: int, token: str = Depends(verify_token)):
    return {
        "conversacionId": conv_id, 
        "mensajes": [
            {
                "id": 1,
                "tipo_mensaje": "pregunta", 
                "contenido": "Â¿CuÃ¡ntos estudiantes hay?",
                "timestamp": datetime.now().isoformat()
            }
        ]
    }

# Handler para Vercel
from mangum import Mangum
handler = Mangum(app)